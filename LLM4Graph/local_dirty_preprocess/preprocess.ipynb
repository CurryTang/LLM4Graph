{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os.path as osp\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "from torch_geometric.utils import coalesce\n",
    "\n",
    "data_path = \"/mnt/home/chenzh85/LLMGNN/data\"\n",
    "data_name = ['cora', 'citeseer', 'pubmed', 'wikics', 'arxiv', 'products']\n",
    "\n",
    "for name in data_name:\n",
    "    prefix = name\n",
    "    if name == 'citeseer':\n",
    "        filename = osp.join(data_path, \"citeseer2_fixed_sbert.pt\")\n",
    "    else:\n",
    "        filename = osp.join(data_path, \"{}_fixed_sbert.pt\")\n",
    "\n",
    "    new_filename = osp.join(data_path, \"{}_sbert.pt\")\n",
    "    \n",
    "    ## remove duplicated edges\n",
    "    data = torch.load(filename.format(prefix))\n",
    "\n",
    "    raw_texts = data.raw_texts\n",
    "\n",
    "    if name == 'cora' or name == 'wikics' or name == 'products':\n",
    "        splits = [x.split(':', 1) for x in raw_texts]\n",
    "        title = [x[0].strip() for x in splits]\n",
    "        content = [x[1].strip() for x in splits]\n",
    "        df = pd.DataFrame({'title': title, 'content': content})\n",
    "    elif name == 'pubmed':\n",
    "        splits = [x.split('\\n', 1) for x in raw_texts]\n",
    "        title = [x[0].strip() for x in splits]\n",
    "        content = [x[1].strip() for x in splits]\n",
    "        title = [t.replace('Title:', '').strip() for t in title]\n",
    "        content = [c.replace('Abstract:', '').strip() for c in content]\n",
    "        df = pd.DataFrame({'title': title, 'content': content})\n",
    "    elif name == 'arxiv':\n",
    "        raw = pd.read_csv(/mnt/home/chenzh85/graphlang/ogb_arxiv.csv)\n",
    "        raw = raw[['title', 'abstract']]\n",
    "        df = raw.rename(columns={'title': 'title', 'abstract': 'content'})\n",
    "    else:\n",
    "        df = pd.DataFrame({'content': raw_texts})\n",
    "    \n",
    "    df.to_parquet(osp.join(data_path, \"{}_raw.parquet\".format(prefix)), compression='snappy')\n",
    "\n",
    "    del data.raw_texts\n",
    "\n",
    "    del data.train_masks\n",
    "\n",
    "    del data.val_masks\n",
    "\n",
    "    del data.test_masks\n",
    "\n",
    "    del data.category_names\n",
    "\n",
    "    no_duplicate_edge_index = coalesce(data.edge_index)\n",
    "\n",
    "    data.edge_index = no_duplicate_edge_index\n",
    "\n",
    "    torch.save(data, new_filename.format(prefix))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ood preprocess"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acl24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
